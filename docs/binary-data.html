<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Applied Statistics II</title>
  <meta name="description" content="Course notes for MATH 456 at CSU Chico">
  <meta name="generator" content="bookdown 0.5.15 and GitBook 2.6.7">

  <meta property="og:title" content="Applied Statistics II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MATH 456 at CSU Chico" />
  <meta name="github-repo" content="norcalbiostat/MATH456_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Applied Statistics II" />
  
  <meta name="twitter:description" content="Course notes for MATH 456 at CSU Chico" />
  

<meta name="author" content="Robin A. Donatello and Edward A. Roualdes">


<meta name="date" content="2018-01-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="fitting-glms-in-r.html">
<link rel="next" href="categorical-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Statistics II course notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="data-prep.html"><a href="data-prep.html"><i class="fa fa-check"></i><b>1</b> Preparing Data for Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="reproducible-workflows.html"><a href="reproducible-workflows.html"><i class="fa fa-check"></i><b>1.1</b> Reproducible Workflows</a></li>
<li class="chapter" data-level="1.2" data-path="identifying-variable-types.html"><a href="identifying-variable-types.html"><i class="fa fa-check"></i><b>1.2</b> Identifying Variable Types</a></li>
<li class="chapter" data-level="1.3" data-path="data-editing-and-recoding.html"><a href="data-editing-and-recoding.html"><i class="fa fa-check"></i><b>1.3</b> Data Editing and Recoding</a></li>
<li class="chapter" data-level="1.4" data-path="outliers.html"><a href="outliers.html"><i class="fa fa-check"></i><b>1.4</b> Outliers</a></li>
<li class="chapter" data-level="1.5" data-path="data-transformations.html"><a href="data-transformations.html"><i class="fa fa-check"></i><b>1.5</b> Data Transformations</a></li>
<li class="chapter" data-level="1.6" data-path="selecting-appropriate-analysis.html"><a href="selecting-appropriate-analysis.html"><i class="fa fa-check"></i><b>1.6</b> Selecting Appropriate Analysis</a></li>
<li class="chapter" data-level="1.7" data-path="wide-vs-long-data.html"><a href="wide-vs-long-data.html"><i class="fa fa-check"></i><b>1.7</b> Wide vs.Â Long data</a></li>
</ul></li>
<li class="part"><span><b>I Regression Modeling</b></span></li>
<li class="chapter" data-level="2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="mathmatical-model.html"><a href="mathmatical-model.html"><i class="fa fa-check"></i><b>2.1</b> Mathmatical Model</a></li>
<li class="chapter" data-level="2.2" data-path="parameter-estimates.html"><a href="parameter-estimates.html"><i class="fa fa-check"></i><b>2.2</b> Parameter Estimates</a></li>
<li class="chapter" data-level="2.3" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>2.3</b> Interval estimation</a></li>
<li class="chapter" data-level="2.4" data-path="corelation-coefficient.html"><a href="corelation-coefficient.html"><i class="fa fa-check"></i><b>2.4</b> Corelation Coefficient</a></li>
<li class="chapter" data-level="2.5" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>2.5</b> Assumptions</a></li>
<li class="chapter" data-level="2.6" data-path="example.html"><a href="example.html"><i class="fa fa-check"></i><b>2.6</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="types-of-x-variables.html"><a href="types-of-x-variables.html"><i class="fa fa-check"></i><b>3.1</b> Types of X variables</a></li>
<li class="chapter" data-level="3.2" data-path="mathematical-model.html"><a href="mathematical-model.html"><i class="fa fa-check"></i><b>3.2</b> Mathematical Model</a></li>
<li class="chapter" data-level="3.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>3.3</b> Parameter Estimation</a></li>
<li class="chapter" data-level="3.4" data-path="example-1.html"><a href="example-1.html"><i class="fa fa-check"></i><b>3.4</b> Example</a></li>
<li class="chapter" data-level="3.5" data-path="model-diagnostics.html"><a href="model-diagnostics.html"><i class="fa fa-check"></i><b>3.5</b> Model Diagnostics</a></li>
<li class="chapter" data-level="3.6" data-path="multicollinearity.html"><a href="multicollinearity.html"><i class="fa fa-check"></i><b>3.6</b> Multicollinearity</a></li>
<li class="chapter" data-level="3.7" data-path="what-to-watch-out-for.html"><a href="what-to-watch-out-for.html"><i class="fa fa-check"></i><b>3.7</b> What to watch out for</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>4</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="fitting-glms-in-r.html"><a href="fitting-glms-in-r.html"><i class="fa fa-check"></i><b>4.1</b> Fitting GLMs in R</a></li>
<li class="chapter" data-level="4.2" data-path="binary-data.html"><a href="binary-data.html"><i class="fa fa-check"></i><b>4.2</b> Binary Data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="binary-data.html"><a href="binary-data.html#example-the-effect-of-gender-on-depression"><i class="fa fa-check"></i><b>4.2.1</b> Example: The effect of gender on Depression</a></li>
<li class="chapter" data-level="4.2.2" data-path="binary-data.html"><a href="binary-data.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="binary-data.html"><a href="binary-data.html#interpretation"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="binary-data.html"><a href="binary-data.html#goodness-of-fit"><i class="fa fa-check"></i><b>4.2.4</b> Goodness of Fit</a></li>
<li class="chapter" data-level="4.2.5" data-path="binary-data.html"><a href="binary-data.html#classification"><i class="fa fa-check"></i><b>4.2.5</b> Classification</a></li>
<li class="chapter" data-level="4.2.6" data-path="binary-data.html"><a href="binary-data.html#calculating-predictions"><i class="fa fa-check"></i><b>4.2.6</b> Calculating predictions</a></li>
<li class="chapter" data-level="4.2.7" data-path="binary-data.html"><a href="binary-data.html#model-performance"><i class="fa fa-check"></i><b>4.2.7</b> Model Performance</a></li>
<li class="chapter" data-level="4.2.8" data-path="binary-data.html"><a href="binary-data.html#roc-curves"><i class="fa fa-check"></i><b>4.2.8</b> ROC Curves</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data.html"><a href="categorical-data.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data</a></li>
<li class="chapter" data-level="4.4" data-path="count-data.html"><a href="count-data.html"><i class="fa fa-check"></i><b>4.4</b> Count Data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-building.html"><a href="model-building.html"><i class="fa fa-check"></i><b>5</b> Model Building</a><ul>
<li class="chapter" data-level="5.1" data-path="categorical-predictors.html"><a href="categorical-predictors.html"><i class="fa fa-check"></i><b>5.1</b> Categorical Predictors</a><ul>
<li class="chapter" data-level="5.1.1" data-path="categorical-predictors.html"><a href="categorical-predictors.html#factor-variable-coding"><i class="fa fa-check"></i><b>5.1.1</b> Factor variable coding</a></li>
<li class="chapter" data-level="5.1.2" data-path="categorical-predictors.html"><a href="categorical-predictors.html#wald-test"><i class="fa fa-check"></i><b>5.1.2</b> Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stratification.html"><a href="stratification.html"><i class="fa fa-check"></i><b>5.2</b> Stratification</a></li>
<li class="chapter" data-level="5.3" data-path="moderation.html"><a href="moderation.html"><i class="fa fa-check"></i><b>5.3</b> Moderation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="moderation.html"><a href="moderation.html#example-2"><i class="fa fa-check"></i><b>5.3.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>5.4</b> Interactions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interactions.html"><a href="interactions.html#example-3"><i class="fa fa-check"></i><b>5.4.1</b> Example</a></li>
<li class="chapter" data-level="5.4.2" data-path="interactions.html"><a href="interactions.html#example-4"><i class="fa fa-check"></i><b>5.4.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variable-selection-process.html"><a href="variable-selection-process.html"><i class="fa fa-check"></i><b>5.5</b> Variable Selection Process</a><ul>
<li class="chapter" data-level="5.5.1" data-path="variable-selection-process.html"><a href="variable-selection-process.html#confounding"><i class="fa fa-check"></i><b>5.5.1</b> Confounding</a></li>
<li class="chapter" data-level="5.5.2" data-path="variable-selection-process.html"><a href="variable-selection-process.html#automated-selection-procedures"><i class="fa fa-check"></i><b>5.5.2</b> Automated selection procedures</a></li>
<li class="chapter" data-level="5.5.3" data-path="variable-selection-process.html"><a href="variable-selection-process.html#best-subsets-pma5-section-8.7"><i class="fa fa-check"></i><b>5.5.3</b> Best Subsets (PMA5 Section 8.7)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="comparing-between-models.html"><a href="comparing-between-models.html"><i class="fa fa-check"></i><b>5.6</b> Comparing between models</a></li>
<li class="chapter" data-level="5.7" data-path="what-to-watch-out-for-1.html"><a href="what-to-watch-out-for-1.html"><i class="fa fa-check"></i><b>5.7</b> What to watch out for</a></li>
</ul></li>
<li class="part"><span><b>II Multivariate Analysis</b></span></li>
<li class="chapter" data-level="6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>6</b> Principal Component Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="basic-idea.html"><a href="basic-idea.html"><i class="fa fa-check"></i><b>6.1</b> Basic Idea</a></li>
<li class="chapter" data-level="6.2" data-path="more-generally.html"><a href="more-generally.html"><i class="fa fa-check"></i><b>6.2</b> More Generally</a></li>
<li class="chapter" data-level="6.3" data-path="calculating-c.html"><a href="calculating-c.html"><i class="fa fa-check"></i><b>6.3</b> Calculating C</a></li>
<li class="chapter" data-level="6.4" data-path="using-the-correlation-matrix.html"><a href="using-the-correlation-matrix.html"><i class="fa fa-check"></i><b>6.4</b> Using the correlation matrix</a></li>
<li class="chapter" data-level="6.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>6.5</b> Data Reduction</a></li>
<li class="chapter" data-level="6.6" data-path="example-analysis-of-depression.html"><a href="example-analysis-of-depression.html"><i class="fa fa-check"></i><b>6.6</b> Example Analysis of depression</a></li>
<li class="chapter" data-level="6.7" data-path="use-in-multiple-regression.html"><a href="use-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.7</b> Use in Multiple Regression</a></li>
<li class="chapter" data-level="6.8" data-path="things-to-watch-out-for.html"><a href="things-to-watch-out-for.html"><i class="fa fa-check"></i><b>6.8</b> Things to watch out for</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="fa.html"><a href="fa.html"><i class="fa fa-check"></i><b>7</b> Factor Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="stuff.html"><a href="stuff.html"><i class="fa fa-check"></i><b>7.1</b> stuff</a></li>
</ul></li>
<li class="part"><span><b>III Multi-level Analysis</b></span></li>
<li class="chapter" data-level="8" data-path="RI.html"><a href="RI.html"><i class="fa fa-check"></i><b>8</b> Random Intercept Models</a></li>
<li class="chapter" data-level="9" data-path="longitudinal.html"><a href="longitudinal.html"><i class="fa fa-check"></i><b>9</b> Longitudinal Data</a></li>
<li class="chapter" data-level="10" data-path="spatial.html"><a href="spatial.html"><i class="fa fa-check"></i><b>10</b> Spatial Data</a></li>
<li class="part"><span><b>IV Other Topics</b></span></li>
<li class="chapter" data-level="11" data-path="mda.html"><a href="mda.html"><i class="fa fa-check"></i><b>11</b> Missing Data</a><ul>
<li class="chapter" data-level="11.1" data-path="identifying-missing-data.html"><a href="identifying-missing-data.html"><i class="fa fa-check"></i><b>11.1</b> Identifying missing data</a><ul>
<li class="chapter" data-level="11.1.1" data-path="identifying-missing-data.html"><a href="identifying-missing-data.html#visualize-missing-patterns"><i class="fa fa-check"></i><b>11.1.1</b> Visualize missing patterns</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="effects-of-nonresponse.html"><a href="effects-of-nonresponse.html"><i class="fa fa-check"></i><b>11.2</b> Effects of Nonresponse</a></li>
<li class="chapter" data-level="11.3" data-path="missing-data-mechanisms.html"><a href="missing-data-mechanisms.html"><i class="fa fa-check"></i><b>11.3</b> Missing Data Mechanisms</a><ul>
<li class="chapter" data-level="11.3.1" data-path="missing-data-mechanisms.html"><a href="missing-data-mechanisms.html#demonstration-via-simulation"><i class="fa fa-check"></i><b>11.3.1</b> Demonstration via Simulation</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="general-strategies.html"><a href="general-strategies.html"><i class="fa fa-check"></i><b>11.4</b> General strategies</a><ul>
<li class="chapter" data-level="11.4.1" data-path="general-strategies.html"><a href="general-strategies.html#complete-cases-analysis"><i class="fa fa-check"></i><b>11.4.1</b> Complete cases analysis</a></li>
<li class="chapter" data-level="11.4.2" data-path="general-strategies.html"><a href="general-strategies.html#available-case-analysis"><i class="fa fa-check"></i><b>11.4.2</b> Available-case analysis</a></li>
<li class="chapter" data-level="11.4.3" data-path="general-strategies.html"><a href="general-strategies.html#imputation"><i class="fa fa-check"></i><b>11.4.3</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="imputation-methods.html"><a href="imputation-methods.html"><i class="fa fa-check"></i><b>11.5</b> Imputation Methods</a></li>
<li class="chapter" data-level="11.6" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html"><i class="fa fa-check"></i><b>11.6</b> Multiple Imputation (MI)</a><ul>
<li class="chapter" data-level="11.6.1" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#goals"><i class="fa fa-check"></i><b>11.6.1</b> Goals</a></li>
<li class="chapter" data-level="11.6.2" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#technique"><i class="fa fa-check"></i><b>11.6.2</b> Technique</a></li>
<li class="chapter" data-level="11.6.3" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#mi-as-a-paradigm"><i class="fa fa-check"></i><b>11.6.3</b> MI as a paradigm</a></li>
<li class="chapter" data-level="11.6.4" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#inference-on-mi"><i class="fa fa-check"></i><b>11.6.4</b> Inference on MI</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html"><i class="fa fa-check"></i><b>11.7</b> Multiple Imputation using Chained Equations (MICE)</a><ul>
<li class="chapter" data-level="11.7.1" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html#visualize-imputations"><i class="fa fa-check"></i><b>11.7.1</b> Visualize Imputations</a></li>
<li class="chapter" data-level="11.7.2" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html#calculating-bias"><i class="fa fa-check"></i><b>11.7.2</b> Calculating bias</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="final-thoughts.html"><a href="final-thoughts.html"><i class="fa fa-check"></i><b>11.8</b> Final thoughts</a></li>
<li class="chapter" data-level="11.9" data-path="additional-references.html"><a href="additional-references.html"><i class="fa fa-check"></i><b>11.9</b> Additional References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Statistics II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="binary-data" class="section level2">
<h2><span class="header-section-number">4.2</span> Binary Data</h2>
<p>Goals:</p>
<ul>
<li>Assess the impact selected covariates have on the probability of an outcome occurring.</li>
<li>Predict the likelihood / chance / probability of an event occurring given a certain covariate pattern.</li>
</ul>
<p>Binary data can be fit using a <em>Logistic Model</em> or a <em>Probit Model</em>.</p>
<p>Consider an outcome variable <span class="math inline">\(Y\)</span> with two levels: Y = 1 if event, = 0 if no event.</p>
<p>Let <span class="math inline">\(p_{i} = P(y_{i}=1)\)</span>.</p>
<p>The logistic model relates the probability of an event based on a linear combination of Xâs.</p>
<p><span class="math display">\[
log\left(
\frac{p_{i}}{1-p_{i}}
\right) = \beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}
\]</span></p>
<p>Since the <em>odds</em> are defined as the probability an event occurs divided by the probability it does not occur: <span class="math inline">\((p/(1-p))\)</span>, the function <span class="math inline">\(log\left(\frac{p_{i}}{1-p_{i}}\right)\)</span> is also known as the <em>log odds</em>, or more commonly called the <strong><em>logit</em></strong>. This is the <em>link</em> function for the logistic regression model.</p>
<p><img src="GLM_files/figure-html/unnamed-chunk-3-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This in essence takes a binary outcome 0/1 variable, turns it into a continuous probability (which only has a range from 0 to 1) Then the logit(p) has a continuous distribution ranging from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>, which is the same form as a Multiple Linear Regression (continuous outcome modeled on a set of covariates)</p>
<p>Back solving the logistic model for <span class="math inline">\(p_{i} = e^{\beta X} / (1+e^{\beta X})\)</span> gives us the probability of an event.</p>
<p><span class="math display">\[
p_{i} = \frac{e^{\beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}}}
{1 + e^{\beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}}}
\]</span></p>

<div class="rmdtip">
The probit function uses the inverse CDF for the normal distribution as the link function.
</div>

<div id="example-the-effect-of-gender-on-depression" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Example: The effect of gender on Depression</h3>
<p>Is gender associated with depression? Read in the <code>depression</code> data and recode sex to be an indicator of being male.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress &lt;-<span class="st"> </span><span class="kw">read.delim</span>(<span class="st">&quot;https://norcalbiostat.netlify.com/data/depress_081217.txt&quot;</span>)
<span class="kw">names</span>(depress) &lt;-<span class="st"> </span><span class="kw">tolower</span>(<span class="kw">names</span>(depress)) <span class="co"># make all variable names lower case. </span></code></pre></div>
<ul>
<li>Binary outcome variable: Symptoms of Depression (<code>cases</code>)</li>
<li>Binary predictor variable: Gender (<code>sex</code>) as an indicator of being female</li>
</ul>
<p>The outcome <span class="math inline">\(y\)</span> is a 0/1 Bernoulli random variable. The sum of a vector of Bernoulliâs (<span class="math inline">\(\sum_{i=1}^{n}y_{i}\)</span>) has a Binomial distribution. When we specify that <code>family = &quot;binomial&quot;</code> the <code>glm()</code> function auto-assigns âlogitâ link function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dep_sex_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(dep_sex_model)
## 
## Call:
## glm(formula = cases ~ sex, family = &quot;binomial&quot;, data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7023  -0.7023  -0.4345  -0.4345   2.1941  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.3125     0.3315  -6.976 3.04e-12 ***
## sex           1.0386     0.3767   2.757  0.00583 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 259.40  on 292  degrees of freedom
## AIC: 263.4
## 
## Number of Fisher Scoring iterations: 5</code></pre></div>
<p>We exponentiate the coefficients to back transform the <span class="math inline">\(\beta\)</span> estimates into Odds Ratios</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(dep_sex_model))
## (Intercept)         sex 
##   0.0990099   2.8251748</code></pre></div>
<p>Females have 2.8 times the odds of showing signs of depression compared to males.</p>
<p><strong>Confidence Intervals</strong> The OR is <strong>not</strong> a linear function of the <span class="math inline">\(x&#39;s\)</span>, but <span class="math inline">\(\beta\)</span> is. This means that a CI for the OR is created by calculating a CI for <span class="math inline">\(\beta\)</span>, and then exponentiating the endpoints. A 95% CI for the OR can be calculated as:</p>
<p><span class="math display">\[e^{\hat{\beta} \pm 1.96 SE_{\beta}} \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">confint</span>(dep_sex_model))
##                  2.5 %    97.5 %
## (Intercept) 0.04843014 0.1801265
## sex         1.39911056 6.2142384</code></pre></div>
</div>
<div id="multiple-logistic-regression" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Multiple Logistic Regression</h3>
<p>Just like multiple linear regression, additional predictors are simply included in the model using a <code>+</code> symbol.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mvmodel &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(mvmodel)
## 
## Call:
## glm(formula = cases ~ age + income + sex, family = &quot;binomial&quot;, 
##     data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0249  -0.6524  -0.5050  -0.3179   2.5305  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -0.67646    0.57881  -1.169  0.24253   
## age         -0.02096    0.00904  -2.318  0.02043 * 
## income      -0.03656    0.01409  -2.595  0.00946 **
## sex          0.92945    0.38582   2.409  0.01600 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 247.54  on 290  degrees of freedom
## AIC: 255.54
## 
## Number of Fisher Scoring iterations: 5</code></pre></div>
<ul>
<li>The sign of the <span class="math inline">\(\beta\)</span> coefficients can be interpreted in the same manner as with linear regression.</li>
<li>The odds of being depressed are less if the respondent has a higher income and is older, and higher if the respondent is female.</li>
</ul>
</div>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Interpretation</h3>
<ul>
<li>The OR provides a directly understandable statistic for the relationship between <span class="math inline">\(y\)</span> and a specific <span class="math inline">\(x\)</span> given all other <span class="math inline">\(x\)</span>âs in the model are fixed.</li>
<li>For a continuous variable X with slope coefficient <span class="math inline">\(\beta\)</span>, the quantity <span class="math inline">\(e^{b}\)</span> is interpreted as the ratio of the odds for a person with value (X+1) relative to the odds for a person with value X.</li>
<li><span class="math inline">\(exp(kb)\)</span> is the incremental odds ratio corresponding to an increase of <span class="math inline">\(k\)</span> units in the variable X, assuming that the values of all other X variables remain unchanged.</li>
</ul>
<p><strong>Where does <span class="math inline">\(OR = e^{\beta}\)</span> come from?</strong></p>
<p>The full model is: <span class="math display">\[log(odds) = -0.676 - 0.02096*age - .03656*income + 0.92945*gender\]</span></p>
<p>We want to calculate the Odds Ratio of depression for women compared to men. <span class="math display">\[ OR = \frac{Odds (Y=1|F)}{Odds (Y=1|M)} \]</span></p>
<p>Write out the equations for men and women separately. <span class="math display">\[ = \frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945(1)}}
          {e^{-0.676 - 0.02096*age - .03656*income + 0.92945(0)}}\]</span></p>
<p>Applying rules of exponents to simplify. <span class="math display">\[ = \frac{e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(1)}}
          {e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(0)}}\]</span></p>
<p><span class="math display">\[ = \frac{e^{0.92945(1)}}
          {e^{0.92945(0)}}\]</span></p>
<p><span class="math display">\[ = e^{0.92945} \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(.<span class="dv">92945</span>)
## [1] 2.533116
<span class="kw">exp</span>(<span class="kw">coef</span>(mvmodel)[<span class="dv">4</span>])
##      sex 
## 2.533112</code></pre></div>
<p>The odds of a female being depressed are 2.53 times greater than the odds for Males after adjusting for the linear effects of age and income (p=.016).</p>
<div id="effect-of-a-k-unit-change" class="section level4">
<h4><span class="header-section-number">4.2.3.1</span> Effect of a k unit change</h4>
<p>Sometimes a 1 unit change in a continuous variable is not meaningful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mvmodel))
## (Intercept)         age      income         sex 
##   0.5084157   0.9792605   0.9640969   2.5331122
<span class="kw">exp</span>(<span class="kw">confint</span>(mvmodel))
##                 2.5 %    97.5 %
## (Intercept) 0.1585110 1.5491849
## age         0.9615593 0.9964037
## income      0.9357319 0.9891872
## sex         1.2293435 5.6586150</code></pre></div>
<ul>
<li>The Adjusted odds ratio (AOR) for increase of 1 year of age is 0.98 (95%CI .96, 1.0)</li>
<li>How about a 10 year increase in age? <span class="math inline">\(e^{10*\beta_{age}} = e^{-.21} = .81\)</span></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="dv">10</span><span class="op">*</span><span class="kw">coef</span>(mvmodel)[<span class="dv">2</span>])
##       age 
## 0.8109285</code></pre></div>
<p>with a confidence interval of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">exp</span>(<span class="dv">10</span><span class="op">*</span><span class="kw">confint</span>(mvmodel)[<span class="dv">2</span>,]),<span class="dv">3</span>)
##  2.5 % 97.5 % 
##  0.676  0.965</code></pre></div>
<p>Controlling for gender and income, an individual has 0.81 (95% CI 0.68, 0.97) times the odds of being depressed compared to someone who is 10 years younger than them.</p>
<div id="example-the-relationship-between-income-employment-status-and-depression." class="section level5">
<h5><span class="header-section-number">4.2.3.1.1</span> Example: The relationship between income, employment status and depression.</h5>
<p>This example follows PMA5 Ch 12.7</p>
<p>Here I create the binary indicators of lowincome (annual income &lt;$10k/year) and underemployed (part time or unemployed).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress<span class="op">$</span>lowincome &lt;-<span class="st"> </span><span class="kw">ifelse</span>(depress<span class="op">$</span>income <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="kw">table</span>(depress<span class="op">$</span>lowincome, depress<span class="op">$</span>income, <span class="dt">useNA=</span><span class="st">&quot;always&quot;</span>)
##       
##         2  4  5  6  7  8  9 11 12 13 15 16 18 19 20 23 24 25 26 27 28 31
##   0     0  0  0  0  0  0  0 17  2 18 24  1  1 25  3 25  2  1  1  1 19  1
##   1     7  8 10 12 18 14 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##   &lt;NA&gt;  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##       
##        32 35 36 37 42 45 55 65 &lt;NA&gt;
##   0     1 24  1  1  1 15  9 10    0
##   1     0  0  0  0  0  0  0  0    0
##   &lt;NA&gt;  0  0  0  0  0  0  0  0    0

depress<span class="op">$</span>underemployed &lt;-<span class="st"> </span><span class="kw">ifelse</span>(depress<span class="op">$</span>employ <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PT&quot;</span>, <span class="st">&quot;Unemp&quot;</span>), <span class="dv">1</span>, <span class="dv">0</span> )
<span class="kw">table</span>(depress<span class="op">$</span>underemployed, depress<span class="op">$</span>employ, <span class="dt">useNA=</span><span class="st">&quot;always&quot;</span>)
##       
##         FT Houseperson In School Other  PT Retired Unemp &lt;NA&gt;
##   0    167          27         2     4   0      38     0    0
##   1      0           0         0     0  42       0    14    0
##   &lt;NA&gt;   0           0         0     0   0       0     0    0</code></pre></div>
<p>The <strong>Main Effects</strong> model assumes that the effect of income on depression is independent of employment status, and the effect of employment status on depression is independent of income.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">me_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>lowincome <span class="op">+</span><span class="st"> </span>underemployed, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(me_model)
## 
## Call:
## glm(formula = cases ~ lowincome + underemployed, family = &quot;binomial&quot;, 
##     data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9085  -0.5843  -0.5279  -0.5279   2.0197  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -1.9003     0.2221  -8.556  &lt; 2e-16 ***
## lowincome       0.2192     0.3353   0.654  0.51322    
## underemployed   1.0094     0.3470   2.909  0.00363 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 259.93  on 291  degrees of freedom
## AIC: 265.93
## 
## Number of Fisher Scoring iterations: 4</code></pre></div>
<p>To formally test whether an interaction term is necessary, we add the interaction term into the model and assess whether the coefficient for the interaction term is significantly different from zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">me_intx_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>lowincome <span class="op">+</span><span class="st"> </span>underemployed <span class="op">+</span><span class="st"> </span>lowincome<span class="op">*</span>underemployed, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>) 
<span class="kw">summary</span>(me_intx_model)
## 
## Call:
## glm(formula = cases ~ lowincome + underemployed + lowincome * 
##     underemployed, family = &quot;binomial&quot;, data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3537  -0.5790  -0.5790  -0.4717   2.1219  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)              -1.7011     0.2175  -7.822 5.21e-15 ***
## lowincome                -0.4390     0.4324  -1.015  0.31005    
## underemployed             0.2840     0.4501   0.631  0.52802    
## lowincome:underemployed   2.2615     0.7874   2.872  0.00408 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 251.17  on 290  degrees of freedom
## AIC: 259.17
## 
## Number of Fisher Scoring iterations: 4</code></pre></div>
</div>
</div>
</div>
<div id="goodness-of-fit" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Goodness of Fit</h3>
<ul>
<li>Tests to see if there is sufficient reason to believe that the logistic model does not fit (<span class="math inline">\(H_{a}\)</span>), versus it does fit (<span class="math inline">\(H_{0}\)</span>)</li>
<li>This means that a small p-value indicates that the model <em>does not fit</em> the data.</li>
<li>Weâll look specifically at the Hosmer-Lemeshow (HL) Goodness of fit (GoF) test</li>
</ul>
<div id="hl-gof" class="section level4">
<h4><span class="header-section-number">4.2.4.1</span> HL GoF</h4>
<ol style="list-style-type: decimal">
<li>Compute the probability (<span class="math inline">\(p_{i}\)</span>) of event (risk) for each observation.</li>
<li>Sort data by this <span class="math inline">\(p\)</span>.</li>
<li>Divide into <span class="math inline">\(G\)</span> equal sized groups in ascending order (G=10 is common, i.e.Â split into deciles)</li>
<li>Then for each group we calculate
<ul>
<li><span class="math inline">\(O_{1g}\)</span>: the observed number of events</li>
<li><span class="math inline">\(E_{1g}\)</span>: the expected number of events as the <span class="math inline">\(\sum_{i} p_{ig}\)</span></li>
<li><span class="math inline">\(O_{0g}\)</span>: the observed number of non-events</li>
<li><span class="math inline">\(E_{0g}\)</span>: the expected number of events as the <span class="math inline">\(1-\sum_{i} p_{ig}\)</span></li>
</ul></li>
<li>Then the HL test statistic (<span class="math inline">\(H\)</span>) has a <span class="math inline">\(\chi^{2}\)</span> distribution and is is calculated as:</li>
</ol>
<p><span class="math display">\[ 
  H = \sum_{g=1}^{G}\left({\frac {(O_{1g}-E_{1g})^{2}}{E_{1g}}}+{\frac {(O_{0g}-E_{0g})^{2}}{E_{0g}}}\right) \sim \chi^{2}_{G-2}
\]</span></p>
</div>
<div id="hl-gof-in-r" class="section level4">
<h4><span class="header-section-number">4.2.4.2</span> HL GoF in R</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MKmisc)
<span class="kw">HLgof.test</span>(<span class="dt">fit =</span> <span class="kw">fitted</span>(me_intx_model), <span class="dt">obs =</span> me_intx_model<span class="op">$</span>y)
## $C
## 
##  Hosmer-Lemeshow C statistic
## 
## data:  fitted(me_intx_model) and me_intx_model$y
## X-squared = 2.2294e-16, df = 2, p-value = 1
## 
## 
## $H
## 
##  Hosmer-Lemeshow H statistic
## 
## data:  fitted(me_intx_model) and me_intx_model$y
## X-squared = 5.614e-17, df = 8, p-value = 1</code></pre></div>
<p>A very low test statistic and a very high p-value indicate that this model fits the data well.</p>
</div>
</div>
<div id="classification" class="section level3">
<h3><span class="header-section-number">4.2.5</span> Classification</h3>
<ul>
<li>Sometimes Odds Ratios can be difficult to interpret or understand.</li>
<li>Sometimes you just want to report the probability of the event occurring.</li>
<li>Or sometimes you want to predict whether or not a new individual is going to have the event.</li>
</ul>
<p>For all of these, we need to calculate <span class="math inline">\(p_{i} = P(y_{i}=1)\)</span>, the probability of the event.</p>
<p>For the main effects model of depression on age, income and gender the predicted probability of depression is: <span class="math display">\[
P(depressed) = \frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945*gender}}
{1 + e^{-0.676 - 0.02096*age - .03656*income + 0.92945*gender}}
\]</span></p>
<p>Letâs compare the probability of being depressed for males and females separately, while holding age and income constant at their average value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">age=</span><span class="kw">mean</span>(age), <span class="dt">income=</span><span class="kw">mean</span>(income))
##        age   income
## 1 44.41497 20.57483</code></pre></div>
<p>Plug the coefficient estimates and the values of the variables into the equation and calculate. <span class="math display">\[
P(depressed|Female) = \frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}
{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">XB.f &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.676</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.02096</span><span class="op">*</span>(<span class="fl">44.4</span>) <span class="op">-</span><span class="st"> </span>.<span class="dv">03656</span><span class="op">*</span>(<span class="fl">20.6</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.92945</span>
<span class="kw">exp</span>(XB.f) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(XB.f))
## [1] 0.1930504</code></pre></div>
<p><span class="math display">\[
P(depressed|Male) = \frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}
{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">XB.m &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.676</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.02096</span><span class="op">*</span>(<span class="fl">44.4</span>) <span class="op">-</span><span class="st"> </span>.<span class="dv">03656</span><span class="op">*</span>(<span class="fl">20.6</span>)
<span class="kw">exp</span>(XB.m) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(XB.m))
## [1] 0.08629312</code></pre></div>
<p>The probability for a 44.4 year old female who makes $20.6k annual income has a 0.19 probability of being depressed. The probability of depression for a male of equal age and income is 0.86.</p>
</div>
<div id="calculating-predictions" class="section level3">
<h3><span class="header-section-number">4.2.6</span> Calculating predictions</h3>
<p>So what if you want to get the model predicted probability of the event for all individuals in the data set? Thereâs no way Iâm doing that calculation for every person in the data set.</p>
<p>Using the main effects model from above, stored in the object <code>mvmodel</code>, we can call the <code>predict()</code> command to generate a vector of predictions for each row used in the model.</p>

<div class="rmdcaution">
Any row with missing data on any variable used in the model will NOT get a predicted value.
</div>

<p>The <code>predict()</code> function can calculate predictions for any GLM. The model object <code>mvmodel</code> stores the information that it was a logistic regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.pred.prob &lt;-<span class="st"> </span><span class="kw">predict</span>(mvmodel, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)
<span class="kw">head</span>(model.pred.prob)
##          1          2          3          4          5          6 
## 0.21108906 0.08014012 0.15266203 0.24527840 0.15208679 0.17056409</code></pre></div>
<div id="distribution-of-predictions" class="section level4">
<h4><span class="header-section-number">4.2.6.1</span> Distribution of Predictions</h4>
<p>How well does our model do to predict depression?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
plot.mpp &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">prediction =</span> model.pred.prob, 
                       <span class="dt">truth =</span> <span class="kw">factor</span>(mvmodel<span class="op">$</span>y, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Not Depressed&quot;</span>, <span class="st">&quot;Depressed&quot;</span>)))

<span class="kw">ggplot</span>(plot.mpp, <span class="kw">aes</span>(<span class="dt">x=</span>truth, <span class="dt">y=</span>prediction, <span class="dt">fill=</span>truth)) <span class="op">+</span><span class="st"> </span>
<span class="st">      </span><span class="kw">geom_jitter</span>(<span class="dt">width=</span>.<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_violin</span>(<span class="dt">alpha=</span>.<span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><img src="images/q.png" /> What things can you infer from this plot?</p>
<p><img src="images/q.png" /> Where should we put the cutoff value? At what probability should we classify a record as âdepressedâ?</p>
</div>
</div>
<div id="model-performance" class="section level3">
<h3><span class="header-section-number">4.2.7</span> Model Performance</h3>
<ul>
<li>Say we decide that a value of 0.15 is our optimal cutoff value.</li>
<li>We can use this probability to classify each row into groups.
<ul>
<li>The assigned class values must match the data type and levels of the true value.</li>
<li>It also has to be in the same order, so the <code>0</code> group needs to come first.</li>
</ul></li>
<li>Then we calculate a <a href="https://en.wikipedia.org/wiki/Confusion_matrix">[Confusion Matrix]</a> using the similarly named function from the <code>caret</code> package.
<ul>
<li>At itâs core, this is a 2x2 table containing counts of each combination of predicted value and true value.</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)

plot.mpp<span class="op">$</span>pred.class &lt;-<span class="st"> </span><span class="kw">ifelse</span>(plot.mpp<span class="op">$</span>prediction <span class="op">&lt;</span><span class="fl">0.15</span>, <span class="dv">0</span>,<span class="dv">1</span>)
plot.mpp<span class="op">$</span>pred.class &lt;-<span class="st"> </span><span class="kw">factor</span>(plot.mpp<span class="op">$</span>pred.class, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Not Depressed&quot;</span>, <span class="st">&quot;Depressed&quot;</span>))

<span class="kw">confusionMatrix</span>(plot.mpp<span class="op">$</span>pred.class, plot.mpp<span class="op">$</span>truth, <span class="dt">positive=</span><span class="st">&quot;Depressed&quot;</span>)
## Confusion Matrix and Statistics
## 
##                Reference
## Prediction      Not Depressed Depressed
##   Not Depressed           123        10
##   Depressed               121        40
##                                           
##                Accuracy : 0.5544          
##                  95% CI : (0.4956, 0.6121)
##     No Information Rate : 0.8299          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : 0.1615          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.8000          
##             Specificity : 0.5041          
##          Pos Pred Value : 0.2484          
##          Neg Pred Value : 0.9248          
##              Prevalence : 0.1701          
##          Detection Rate : 0.1361          
##    Detection Prevalence : 0.5476          
##       Balanced Accuracy : 0.6520          
##                                           
##        &#39;Positive&#39; Class : Depressed       
## </code></pre></div>
<ul>
<li>123 people were correctly predicted to not be depressed (True Negative, <span class="math inline">\(n_{11}\)</span>)</li>
<li>121 people were incorrectly predicted to be depressed (False Positive, <span class="math inline">\(n_{21}\)</span>)</li>
<li>10 people were incorrectly predicted to not be depressed (False Negative, <span class="math inline">\(n_{12}\)</span>)</li>
<li>40 people were correctly predicted to be depressed (True Positive, <span class="math inline">\(n_{22}\)</span>)</li>
</ul>
<p>Other terminology:</p>
<ul>
<li><strong>Sensitivity/Recall/True positive rate</strong>: P(condition positive|predicted positive) = <code>40/(10+40) = .8</code></li>
<li><strong>Specificity/true negative rate</strong>: P(condition negative|predicted negative) = <code>123/(123+121) = .504</code></li>
<li><strong>Precision/positive predicted value</strong>: P(true positive | predicted positive) = <code>40/(121+40) = .2484</code></li>
<li><strong>Accuracy</strong>: (TP + TN)/ Total: <code>(40 + 123)/(40+123+121+10) = .5544</code></li>
<li><strong>Balanced Accuracy</strong>: <span class="math inline">\([(n_{11}/n_{.1}) + (n_{22}/n_{.2})]/2\)</span> - This is to adjust for class size imbalances (like in this example)</li>
<li><strong>F1 score</strong>: the harmonic mean of precision and recall. This ranges from 0 (bad) to 1 (good): <span class="math inline">\(2*\frac{precision*recall}{precision + recall}\)</span> = <code>2*(.2484*.8)/(.2484+.8) = .38</code></li>
</ul>
<div id="optimal-cutoff-value" class="section level4">
<h4><span class="header-section-number">4.2.7.1</span> Optimal Cutoff Value</h4>
<p>Often we adjust the cutoff value to improve accuracy. This is where we have to put our gut feeling of what probability constitutes âhigh riskâ. For some models, this could be as low as 30%. Itâs whatever the probability is that optimally separates the classes. Letâs look at two ways to visualize model performance as a function of cutoff.</p>
</div>
</div>
<div id="roc-curves" class="section level3">
<h3><span class="header-section-number">4.2.8</span> ROC Curves</h3>
<ul>
<li>We can create a Receiver operating characteristic (ROC) curve to help find that sweet spot.</li>
<li>ROC curves show the balance between sensitivity and specificity.</li>
<li>Weâll use the <a href="https://rocr.bioinf.mpi-sb.mpg.de/">[ROCR]</a> package. It only takes 3 commands:
<ul>
<li>calculate <code>prediction()</code> using the model</li>
<li>calculate the model <code>performance()</code> on both true positive rate and true negative rate for a whole range of cutoff values.</li>
<li><code>plot</code> the curve.
<ul>
<li>The <code>colorize</code> option colors the curve according to the probability cutoff point.</li>
</ul></li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ROCR)
pr &lt;-<span class="st"> </span><span class="kw">prediction</span>(model.pred.prob, mvmodel<span class="op">$</span>y)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pr, <span class="dt">measure=</span><span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure=</span><span class="st">&quot;fpr&quot;</span>)
<span class="kw">plot</span>(perf, <span class="dt">colorize=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">print.cutoffs.at=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.1</span>)))
<span class="kw">abline</span>(<span class="dt">a=</span><span class="dv">0</span>, <span class="dt">b=</span><span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>We can also use the <code>performance()</code> function and say we want to evaluate the <span class="math inline">\(f1\)</span> measure</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">perf.f1 &lt;-<span class="st"> </span><span class="kw">performance</span>(pr,<span class="dt">measure=</span><span class="st">&quot;f&quot;</span>)
<span class="kw">plot</span>(perf.f1)</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>ROC curves:</p>
<ul>
<li>Can also be used for model comparison: <a href="http://yaojenkuo.io/diamondsROC.html" class="uri">http://yaojenkuo.io/diamondsROC.html</a></li>
<li>The Area under the Curve an give you a measure of overall model accuracy by calculating the area under the curve (auc).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pr, <span class="dt">measure=</span><span class="st">&#39;auc&#39;</span>)
auc<span class="op">@</span>y.values
## [[1]]
## [1] 0.695041</code></pre></div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fitting-glms-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="categorical-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
